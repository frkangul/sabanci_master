{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Furkan_Gul_Question4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fufxQ_DsNYY",
        "outputId": "6b3ca9d5-eeda-4d0c-c198-ea845e0ec4ec"
      },
      "source": [
        "# I could not install Spark on local PyCharm application. \n",
        "# That's why I am using Colab as you already suggested in the lecture.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bobSs-b2sQlA",
        "outputId": "07eb480a-4bf5-47ad-9d2c-48163f70d7c4"
      },
      "source": [
        "# Install specific Java and Spark for Python.\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "!pip install pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [1 In\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com] [Conn\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,476 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,751 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,173 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [896 kB]\n",
            "Get:20 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [39.5 kB]\n",
            "Fetched 7,622 kB in 4s (1,815 kB/s)\n",
            "Reading package lists... Done\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 74kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=a7cba007541a6c485d05642d61c02e6718ddc4f0748becbbea34ad6efe503fd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "QbR8NyapsUc7",
        "outputId": "06e977b9-e804-49cb-93a4-1ba9bc5ee256"
      },
      "source": [
        "# Check to see if I installed Spark correctly or not.\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "sc"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8122eaf5b73d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg9x3Z0gz-U3",
        "outputId": "07549d40-da13-42b1-f7a2-dba1f3896fe2"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from itertools import combinations\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "rdd = sc.textFile(\"/content/drive/MyDrive/Colab Notebooks/BDP/Datasets-20210410/Lottery.txt\")  #1995 - 2020\n",
        "\n",
        "rdd = rdd.flatMap(lambda line : line.split('\"rakamlar\":'))\n",
        "rdd = rdd.map(lambda line : line[2:19])\n",
        "rdd = rdd.filter(lambda x : 'bilenKis' not in x)\n",
        "\n",
        "def split_and_combin(line):\n",
        "  lin = line.split(\"#\")\n",
        "  num_list = [int(lin[0]), int(lin[1]), int(lin[2]), int(lin[3]), int(lin[4]), int(lin[5])]\n",
        "  # I examined the dataset and saw that the lottery numbers seem already sorted. But let's sort it for guarantee.\n",
        "  num_list.sort()\n",
        "  # itertools.combinations(iterable, r) has the followin property: If the input iterable is sorted, the combination tuples will be produced in sorted order.\n",
        "  # So there is no need for sorting for later operations since the input (num_list) is already sorted\n",
        "  comb_list = list(combinations(num_list, 3))\n",
        "  return comb_list\n",
        "\n",
        "rdd = rdd.flatMap(lambda x: split_and_combin(x))\n",
        "rdd = rdd.map(lambda x: (x, 1)) # indexing trick\n",
        "rdd = rdd.reduceByKey(lambda x, y: x+y) # reduce operation over the keys\n",
        "rdd = rdd.sortBy(lambda x: x[1], ascending=False) # sort according to possibility in descending\n",
        "print(\"Top 10 most commonly drawn triple numbers (not ordered and the sequence does not matter) in Lottert between 1995 and 2020:\")\n",
        "print(rdd.take(10))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top 10 most commonly drawn triple numbers (not ordered and the sequence does not matter) in Lottert between 1995 and 2020:\n",
            "[((3, 8, 40), 8), ((12, 19, 47), 8), ((1, 21, 24), 8), ((23, 39, 47), 7), ((10, 38, 41), 7), ((1, 24, 42), 7), ((4, 9, 22), 7), ((18, 32, 44), 7), ((5, 38, 41), 7), ((7, 17, 20), 7)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}