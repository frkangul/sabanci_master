{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data in numpy array format\n",
    "data = np.genfromtxt('Data/data1.csv', delimiter=',')\n",
    "data = data[1:,:]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.17022 ,   7.203245, 153.916228],\n",
       "       [  3.023326,   1.467559,  33.652484],\n",
       "       [  1.862602,   3.455607,  68.218691],\n",
       "       [  5.388167,   4.191945, 101.150179],\n",
       "       [  2.044522,   8.781174, 174.900875],\n",
       "       [  6.704675,   4.173048, 107.101716]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check imported DATA\n",
    "data[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:2]\n",
    "y = data[:,2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2, 100)\n",
      "y shape: (1, 100)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.T\n",
    "y = y.T\n",
    "print (\"X shape: \" + str(X.shape))\n",
    "print (\"y shape: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    r = np.maximum(0, Z)\n",
    "    return r\n",
    "\n",
    "def relu_backward(dA, Z):\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    dZ[Z <= 0] = 0    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heInitialization(dim):\n",
    "    w = np.random.randn(dim, 1)*np.sqrt(2/dim)\n",
    "    b = 0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y, lambd):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    Z = np.dot(w.T, X)+b\n",
    "    A = relu(Z)                                  \n",
    "    mse_cost = 1/m*np.sum(np.power((Y-A), 2), axis=1)\n",
    "    L2_regularization_cost = lambd/(2*m)*np.sum(np.square(w))\n",
    "    cost = mse_cost + L2_regularization_cost\n",
    "\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    dA = -2*(Y - A)\n",
    "    dZ = relu_backward(dA, Z)\n",
    "    dw = 1/m*np.dot(X, dZ.T) + lambd/m*w\n",
    "    db = 1/m*np.sum(dZ, axis=1)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    #assert(cost.shape == ())\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, lambd, print_cost = False):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Cost and gradient calculation \n",
    "        grads, cost = propagate(w, b, X, Y, lambd)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (â‰ˆ 2 lines of code)\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 100 training iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, num_iterations = 100000, learning_rate = 0.5, lambd=0.8, print_cost = False):\n",
    "    \n",
    "    w, b = heInitialization(X_train.shape[0])\n",
    "    \n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, lambd, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    d = {\"costs\": costs, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 19578.998517\n",
      "Cost after iteration 100: 13740.796800\n",
      "Cost after iteration 200: 14071.316722\n",
      "Cost after iteration 300: 10411.296468\n",
      "Cost after iteration 400: 13670.081173\n",
      "Cost after iteration 500: 13616.541414\n",
      "Cost after iteration 600: 12663.553728\n",
      "Cost after iteration 700: 11157.960420\n",
      "Cost after iteration 800: 13789.654030\n",
      "Cost after iteration 900: 13073.445831\n",
      "Cost after iteration 1000: 9698.824838\n",
      "Cost after iteration 1100: 13599.454538\n",
      "Cost after iteration 1200: 12172.679734\n",
      "Cost after iteration 1300: 9161.710733\n",
      "Cost after iteration 1400: 12909.715299\n",
      "Cost after iteration 1500: 13428.231410\n",
      "Cost after iteration 1600: 11129.790481\n",
      "Cost after iteration 1700: 13756.546664\n",
      "Cost after iteration 1800: 11947.695838\n",
      "Cost after iteration 1900: 9695.958303\n",
      "Cost after iteration 2000: 13410.934868\n",
      "Cost after iteration 2100: 12795.138266\n",
      "Cost after iteration 2200: 12096.123679\n",
      "Cost after iteration 2300: 12035.512993\n",
      "Cost after iteration 2400: 12726.577818\n",
      "Cost after iteration 2500: 9628.305280\n",
      "Cost after iteration 2600: 9517.461002\n",
      "Cost after iteration 2700: 13084.631525\n",
      "Cost after iteration 2800: 13242.253545\n",
      "Cost after iteration 2900: 13848.698588\n",
      "Cost after iteration 3000: 13951.270604\n",
      "Cost after iteration 3100: 11915.628804\n",
      "Cost after iteration 3200: 12097.788325\n",
      "Cost after iteration 3300: 11778.032590\n",
      "Cost after iteration 3400: 12699.505387\n",
      "Cost after iteration 3500: 13965.452949\n",
      "Cost after iteration 3600: 12366.382580\n",
      "Cost after iteration 3700: 10963.986189\n",
      "Cost after iteration 3800: 10029.800163\n",
      "Cost after iteration 3900: 10488.890722\n",
      "Cost after iteration 4000: 7076.776794\n",
      "Cost after iteration 4100: 13073.637161\n",
      "Cost after iteration 4200: 11219.306061\n",
      "Cost after iteration 4300: 11854.624223\n",
      "Cost after iteration 4400: 10269.726924\n",
      "Cost after iteration 4500: 8569.316342\n",
      "Cost after iteration 4600: 7810.479198\n",
      "Cost after iteration 4700: 13842.571221\n",
      "Cost after iteration 4800: 14286.315188\n",
      "Cost after iteration 4900: 14372.552901\n",
      "Cost after iteration 5000: 11390.546641\n",
      "Cost after iteration 5100: 6937.878398\n",
      "Cost after iteration 5200: 10674.996077\n",
      "Cost after iteration 5300: 13064.124345\n",
      "Cost after iteration 5400: 13220.302891\n",
      "Cost after iteration 5500: 13100.516207\n",
      "Cost after iteration 5600: 11659.437091\n",
      "Cost after iteration 5700: 11341.807448\n",
      "Cost after iteration 5800: 9002.927197\n",
      "Cost after iteration 5900: 9060.793835\n",
      "Cost after iteration 6000: 13549.352245\n",
      "Cost after iteration 6100: 10754.893911\n",
      "Cost after iteration 6200: 11374.936122\n",
      "Cost after iteration 6300: 10945.699327\n",
      "Cost after iteration 6400: 10013.203833\n",
      "Cost after iteration 6500: 8494.881947\n",
      "Cost after iteration 6600: 14825.026668\n",
      "Cost after iteration 6700: 11423.071098\n",
      "Cost after iteration 6800: 13154.769818\n",
      "Cost after iteration 6900: 12843.978535\n",
      "Cost after iteration 7000: 9547.155251\n",
      "Cost after iteration 7100: 10259.327702\n",
      "Cost after iteration 7200: 10685.462791\n",
      "Cost after iteration 7300: 13819.511764\n",
      "Cost after iteration 7400: 14262.717211\n",
      "Cost after iteration 7500: 12590.200288\n",
      "Cost after iteration 7600: 11236.409849\n",
      "Cost after iteration 7700: 9470.595763\n",
      "Cost after iteration 7800: 9873.593049\n",
      "Cost after iteration 7900: 13335.292082\n",
      "Cost after iteration 8000: 12404.812066\n",
      "Cost after iteration 8100: 13003.442604\n",
      "Cost after iteration 8200: 11383.460761\n",
      "Cost after iteration 8300: 11322.990225\n",
      "Cost after iteration 8400: 8988.070415\n",
      "Cost after iteration 8500: 13487.305694\n",
      "Cost after iteration 8600: 11734.400031\n",
      "Cost after iteration 8700: 13249.185684\n",
      "Cost after iteration 8800: 12981.980368\n",
      "Cost after iteration 8900: 14024.401896\n",
      "Cost after iteration 9000: 14486.157764\n",
      "Cost after iteration 9100: 11192.968195\n",
      "Cost after iteration 9200: 10693.425800\n",
      "Cost after iteration 9300: 11404.104997\n",
      "Cost after iteration 9400: 13133.165136\n",
      "Cost after iteration 9500: 11649.887769\n",
      "Cost after iteration 9600: 9612.810560\n",
      "Cost after iteration 9700: 8860.676196\n",
      "Cost after iteration 9800: 9419.189812\n",
      "Cost after iteration 9900: 6209.918035\n"
     ]
    }
   ],
   "source": [
    "d = model(X, y, num_iterations = 10000, learning_rate = 1, lambd= 0, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.49157392],\n",
       "       [120.50573047]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"w\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([213.94984688])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"b\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
